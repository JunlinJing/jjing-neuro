<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="http://localhost:4000/jjing-neuro/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/jjing-neuro/" rel="alternate" type="text/html" /><updated>2025-05-17T11:44:02+02:00</updated><id>http://localhost:4000/jjing-neuro/feed.xml</id><title type="html">Jim Jing</title><subtitle>A personal academic website focusing on neuroscience research and artificial intelligence</subtitle><entry><title type="html">Website Creation: Journey and Overview</title><link href="http://localhost:4000/jjing-neuro/blog/website-creation-overview/" rel="alternate" type="text/html" title="Website Creation: Journey and Overview" /><published>2025-05-17T00:00:00+02:00</published><updated>2025-05-17T00:00:00+02:00</updated><id>http://localhost:4000/jjing-neuro/blog/website-creation-overview</id><content type="html" xml:base="http://localhost:4000/jjing-neuro/blog/website-creation-overview/"><![CDATA[<h1 id="the-birth-of-an-academic-website">The Birth of an Academic Website</h1>

<p>Welcome to my digital home! This website represents both a personal milestone and a platform for sharing my academic pursuits in neuroscience and related fields. In this article, I’ll walk you through how this website came to be, the technologies behind it, and what you can find here.</p>

<h2 id="why-create-a-personal-academic-website">Why Create a Personal Academic Website?</h2>

<p>In today’s interconnected academic landscape, having a personal website serves multiple purposes:</p>

<ul>
  <li>Creating a central hub for research, publications, and projects</li>
  <li>Sharing thoughts and insights through blog posts</li>
  <li>Establishing a professional online presence</li>
  <li>Making research more accessible to colleagues and the public</li>
  <li>Documenting the journey through academia and research</li>
</ul>

<h2 id="the-technical-foundation">The Technical Foundation</h2>

<p>This website is built using Jekyll, a static site generator that offers a perfect balance between simplicity and flexibility. Some of the key technical aspects include:</p>

<ul>
  <li><strong>Jekyll Framework</strong>: Powers the site with its robust templating system</li>
  <li><strong>GitHub Pages</strong>: Hosts the site, offering seamless integration with the development workflow</li>
  <li><strong>Responsive Design</strong>: Ensures the site works well on devices of all sizes</li>
  <li><strong>Dark/Light Mode</strong>: Provides comfortable reading experiences in different lighting conditions</li>
  <li><strong>Category System</strong>: Organizes content in a structured, easily navigable way</li>
</ul>

<h2 id="site-structure-and-content">Site Structure and Content</h2>

<p>The website is organized into several key sections, each serving a specific purpose:</p>

<h3 id="home-page">Home Page</h3>

<p>The homepage provides a quick overview of who I am and features recent updates organized by category. It’s designed to give visitors an immediate sense of my work and interests.</p>

<h3 id="about">About</h3>

<p>The About page offers a more detailed introduction to my background, research interests, and academic journey. It’s where you can learn more about me as a researcher and individual.</p>

<h3 id="research">Research</h3>

<p>This section dives into my research focus areas, current projects, and methodologies. It highlights:</p>

<ul>
  <li>Current research interests in functional connectivity and machine learning</li>
  <li>Ongoing projects and their significance</li>
  <li>Research methodologies and analytical approaches</li>
</ul>

<h3 id="projects">Projects</h3>

<p>The Projects page showcases my open-source initiatives related to neuroscience, including:</p>

<ul>
  <li><strong>ChatPSY</strong>: A mental health assessment system using AI</li>
  <li><strong>BrainDT</strong>: A toolkit for integrating brain databases and resources</li>
  <li><strong>Journal Classification System</strong>: A tool for neuroscience and psychiatry journals</li>
  <li><strong>Neuro Cookbook</strong>: Documentation for neuroscience research tools</li>
  <li><strong>Brain Connectivity Guide</strong>: An accessible introduction to brain connectivity</li>
</ul>

<p>Each project includes details about its purpose, features, and current development status.</p>

<h3 id="blog">Blog</h3>

<p>The blog section is divided into three categories:</p>

<ul>
  <li><strong>Essays</strong>: Reflective pieces on neuroscience, research, and academic life</li>
  <li><strong>Tutorials</strong>: Step-by-step guides for neuroscience research tools and methods</li>
  <li><strong>Ramblings</strong>: More casual thoughts and explorations of ideas at the intersection of science and other domains</li>
</ul>

<h2 id="design-philosophy">Design Philosophy</h2>

<p>When designing this website, I aimed for a balance between academic professionalism and personal expression. Key design principles included:</p>

<ul>
  <li><strong>Clarity</strong>: Clean layouts that prioritize readability</li>
  <li><strong>Accessibility</strong>: Ensuring content is available to all users</li>
  <li><strong>Visual Hierarchy</strong>: Guiding attention to the most important elements</li>
  <li><strong>Consistency</strong>: Maintaining a cohesive look and feel throughout the site</li>
</ul>

<p>The dark mode feature was particularly important, as it helps reduce eye strain during late-night reading sessions—a common scenario for many researchers and students.</p>

<h2 id="challenges-and-solutions">Challenges and Solutions</h2>

<p>Creating this website wasn’t without challenges. Some of the hurdles included:</p>

<ul>
  <li><strong>Responsive Design</strong>: Ensuring content looked good on screens of all sizes</li>
  <li><strong>Dark Mode Implementation</strong>: Creating a system that respects user preferences while maintaining readability</li>
  <li><strong>Content Organization</strong>: Developing a logical structure for diverse content types</li>
  <li><strong>Performance Optimization</strong>: Keeping load times fast while incorporating necessary features</li>
</ul>

<p>Each challenge presented a learning opportunity and led to a better final product.</p>

<h2 id="future-developments">Future Developments</h2>

<p>This website is a living project that will continue to evolve. Future plans include:</p>

<ul>
  <li>Expanding the blog with regular content in all categories</li>
  <li>Adding an interactive bibliography of my publications</li>
  <li>Incorporating more visual elements to illustrate research concepts</li>
  <li>Developing a resources section for fellow researchers</li>
  <li>Implementing internationalization for multilingual access</li>
</ul>

<h2 id="visit-and-explore">Visit and Explore</h2>

<p>I invite you to explore the various sections of this website, engage with the content that interests you, and reach out if you have questions or potential collaborations.</p>

<p>This website represents not just a collection of information, but a reflection of my academic journey and a platform for future growth and connection.</p>

<hr />

<p><em>This article serves as both documentation and an invitation—to explore the site, engage with the content, and perhaps find points of connection in our shared interests in neuroscience and beyond.</em></p>]]></content><author><name>Jim Jing</name></author><category term="essays" /><category term="website" /><category term="jekyll" /><category term="development" /><category term="academic" /><summary type="html"><![CDATA[A behind-the-scenes look at the creation process and features of this academic website]]></summary></entry><entry><title type="html">科学与艺术的交融: 从神经科学视角看创造力</title><link href="http://localhost:4000/jjing-neuro/blog/science-art-intersection/" rel="alternate" type="text/html" title="科学与艺术的交融: 从神经科学视角看创造力" /><published>2025-05-17T00:00:00+02:00</published><updated>2025-05-17T00:00:00+02:00</updated><id>http://localhost:4000/jjing-neuro/blog/science-art-intersection</id><content type="html" xml:base="http://localhost:4000/jjing-neuro/blog/science-art-intersection/"><![CDATA[<h1 id="科学与艺术的交融从神经科学视角看创造力">科学与艺术的交融：从神经科学视角看创造力</h1>

<p>在许多人眼中，科学与艺术代表了思维的两极：一边是理性、系统、分析和严谨，另一边是感性、直觉、表达和自由。然而，作为一名神经科学研究者，我越来越发现这种二分法过于简化了人类认知的复杂性。事实上，最伟大的科学突破往往源于创造性思维，而最感人的艺术作品则常常包含精确的观察和深刻的规律。</p>

<h2 id="创造力的神经基础">创造力的神经基础</h2>

<p>神经科学研究表明，创造性思维涉及大脑多个网络的协同工作。特别是默认模式网络（DMN，负责内部注意力和想象）与执行控制网络（ECN，负责聚焦注意力和决策）之间的动态平衡尤为重要。有趣的是，无论是科学家在实验室冥思苦想，还是艺术家在画布前挥洒灵感，他们的大脑活动模式都展现出惊人的相似性。</p>

<p>在创作状态（或”心流”状态）下，我们会观察到：</p>
<ul>
  <li>额叶皮层活动的减弱，使自我审查和批判性思维暂时降低</li>
  <li>颞顶交界区域活动的增强，促进远距离概念的连接</li>
  <li>前扣带回和岛叶活动的变化，影响情感与认知的整合</li>
</ul>

<p>这些神经活动模式提示我们，创造力并非某些人天生的特质，而是一种可以培养的认知状态。</p>

<h2 id="学科交叉带来的启示">学科交叉带来的启示</h2>

<p>当我沉浸在神经科学研究中时，我常常从艺术中汲取灵感。一幅抽象画作可能启发我思考意识的层次性；一首诗歌的韵律可能让我联想到神经振荡的节奏；一部电影的叙事结构可能映射出记忆形成的过程。</p>

<p>相反，当我欣赏艺术作品时，我的神经科学背景也为我提供了独特的视角。了解视觉皮层如何处理色彩和形状，让我更深入地理解了画家的构图选择；认识到听觉系统如何解析频率和时间模式，使我能够更敏锐地感受音乐的复杂性。</p>

<p>这种跨学科的视角不仅丰富了我的研究和欣赏体验，还促使我思考：也许我们应该重新审视教育体系中对文理分科的固有假设。</p>

<h2 id="打破心智的围墙">打破心智的围墙</h2>

<p>传统教育往往过早地将学生划分为”理科生”或”文科生”，似乎这两条路径必然分离。然而，历史上最具影响力的思想家往往是跨界者：</p>

<ul>
  <li>达·芬奇融合了艺术与工程</li>
  <li>爱因斯坦的物理洞见与他的音乐天赋密不可分</li>
  <li>拉马努金的数学直觉带有几乎神秘主义的色彩</li>
</ul>

<p>在当代，神经科学与艺术的对话正在产生令人兴奋的创新。例如，通过脑电图数据创作的音乐作品；基于神经网络可视化的艺术装置；以及利用大脑活动直接控制的艺术表演。</p>

<h2 id="个人的跨学科之旅">个人的跨学科之旅</h2>

<p>我自己的研究生涯始于对大脑如何处理视觉信息的兴趣，但逐渐发展为对”美”的神经基础的探索。这条路径带我接触了美学理论、艺术史和哲学文献，这些领域的思想极大地丰富了我的科学视角。</p>

<p>同时，我发现写作——无论是科学论文还是这样的随想——都是一种艺术形式。一篇好的科学文章不仅需要严谨的方法和数据，还需要清晰的叙事结构和优雅的表达。在这个意义上，科学家也是讲故事的人。</p>

<h2 id="结语走向整合的思维">结语：走向整合的思维</h2>

<p>随着我们对大脑的理解不断深入，”科学思维”与”艺术思维”的传统二分法可能会逐渐被更整合的认知模型所取代。也许未来的教育将不再强调学科的界限，而是培养学生在不同知识领域间自由穿梭的能力。</p>

<p>在这个信息爆炸、专业化越来越细的时代，保持开放的思维和跨学科的好奇心可能比以往任何时候都更加重要。正如神经科学告诉我们的，创造力往往产生于不同神经网络的对话中；同样，人类最伟大的创新往往诞生于不同学科的交叉地带。</p>

<p>作为研究者，我们探索的不仅是大脑如何工作，还有如何让我们的思维超越固有的范畴和局限。在科学与艺术的交融中，也许我们能找到解答人类最复杂问题的新思路。</p>

<blockquote>
  <p>“逻辑会带你从A到B，想象力能带你去任何地方。” —— 爱因斯坦</p>
</blockquote>

<p>你对科学与艺术关系有什么思考？我很期待在评论区听到你的想法。</p>]]></content><author><name>Jim Jing</name></author><category term="ramblings" /><category term="creativity" /><category term="neuroscience" /><category term="art" /><category term="interdisciplinary" /><summary type="html"><![CDATA[探索神经科学与艺术之间的联系，以及这种跨学科视角如何启发创新思维和创造力。]]></summary></entry><entry><title type="html">A Comprehensive Guide to fMRI Data Preprocessing</title><link href="http://localhost:4000/jjing-neuro/blog/fmri-preprocessing-guide/" rel="alternate" type="text/html" title="A Comprehensive Guide to fMRI Data Preprocessing" /><published>2025-05-17T00:00:00+02:00</published><updated>2025-05-17T00:00:00+02:00</updated><id>http://localhost:4000/jjing-neuro/blog/fmri-preprocessing-guide</id><content type="html" xml:base="http://localhost:4000/jjing-neuro/blog/fmri-preprocessing-guide/"><![CDATA[<h1 id="a-comprehensive-guide-to-fmri-data-preprocessing">A Comprehensive Guide to fMRI Data Preprocessing</h1>

<p>Preprocessing is a critical step in functional MRI analysis that aims to remove unwanted sources of variation and prepare the data for statistical analysis. This tutorial covers the essential preprocessing steps for fMRI data, with practical examples using popular neuroimaging software packages.</p>

<h2 id="why-preprocessing-matters">Why Preprocessing Matters</h2>

<p>Raw fMRI data contains various artifacts and noise sources that can obscure the neural signals of interest:</p>

<ul>
  <li>Head motion during scanning</li>
  <li>Physiological noise (e.g., respiration, cardiac cycles)</li>
  <li>Scanner-related drift</li>
  <li>Timing differences between slice acquisitions</li>
  <li>Anatomical differences between subjects</li>
</ul>

<p>Effective preprocessing minimizes these confounds, enhancing our ability to detect true neural activity and make valid inferences.</p>

<h2 id="required-tools">Required Tools</h2>

<p>For this tutorial, we’ll use:</p>
<ul>
  <li><strong>FSL</strong> (FMRIB Software Library)</li>
  <li><strong>SPM</strong> (Statistical Parametric Mapping)</li>
  <li><strong>Python</strong> with the following libraries:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">nipype</code> (for workflow creation)</li>
      <li><code class="language-plaintext highlighter-rouge">nilearn</code> (for visualization)</li>
      <li><code class="language-plaintext highlighter-rouge">matplotlib</code> (for plotting)</li>
    </ul>
  </li>
</ul>

<h2 id="step-1-dicom-to-nifti-conversion">Step 1: DICOM to NIfTI Conversion</h2>

<p>fMRI data is typically acquired in DICOM format but analyzed in NIfTI format. Here’s how to convert:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">nipype.interfaces.dcm2nii</span> <span class="kn">import</span> <span class="n">Dcm2niix</span>

<span class="n">converter</span> <span class="o">=</span> <span class="n">Dcm2niix</span><span class="p">()</span>
<span class="n">converter</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">source_dir</span> <span class="o">=</span> <span class="s">'path/to/dicom_dir'</span>
<span class="n">converter</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">output_dir</span> <span class="o">=</span> <span class="s">'path/to/output_dir'</span>
<span class="n">converter</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">compress</span> <span class="o">=</span> <span class="s">'y'</span>
<span class="n">converter</span><span class="p">.</span><span class="n">run</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="step-2-removing-initial-volumes">Step 2: Removing Initial Volumes</h2>

<p>The first few volumes of an fMRI run are often discarded to allow for T1 equilibration effects:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">image</span>
<span class="n">fmri_img</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="n">load_img</span><span class="p">(</span><span class="s">'func.nii.gz'</span><span class="p">)</span>
<span class="n">n_vols_to_remove</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">trimmed_img</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="n">index_img</span><span class="p">(</span><span class="n">fmri_img</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="n">n_vols_to_remove</span><span class="p">,</span> <span class="bp">None</span><span class="p">))</span>
<span class="n">trimmed_img</span><span class="p">.</span><span class="n">to_filename</span><span class="p">(</span><span class="s">'func_trimmed.nii.gz'</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="step-3-slice-timing-correction">Step 3: Slice Timing Correction</h2>

<p>Because fMRI volumes are acquired one slice at a time, different slices are actually acquired at different time points:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">nipype.interfaces</span> <span class="kn">import</span> <span class="n">spm</span>
<span class="n">slice_timing</span> <span class="o">=</span> <span class="n">spm</span><span class="p">.</span><span class="n">SliceTiming</span><span class="p">()</span>
<span class="n">slice_timing</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">in_files</span> <span class="o">=</span> <span class="s">'func_trimmed.nii.gz'</span>
<span class="n">slice_timing</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">num_slices</span> <span class="o">=</span> <span class="mi">36</span>
<span class="n">slice_timing</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">time_repetition</span> <span class="o">=</span> <span class="mf">2.0</span>
<span class="n">slice_timing</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">time_acquisition</span> <span class="o">=</span> <span class="mf">2.0</span> <span class="o">-</span> <span class="p">(</span><span class="mf">2.0</span><span class="o">/</span><span class="mi">36</span><span class="p">)</span>
<span class="n">slice_timing</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">slice_order</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">37</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">37</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>  <span class="c1"># Interleaved acquisition
</span><span class="n">slice_timing</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">ref_slice</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">slice_timing</span><span class="p">.</span><span class="n">run</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="step-4-motion-correction">Step 4: Motion Correction</h2>

<p>Subject motion during scanning is one of the biggest sources of noise in fMRI:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">nipype.interfaces</span> <span class="kn">import</span> <span class="n">fsl</span>
<span class="n">mcflirt</span> <span class="o">=</span> <span class="n">fsl</span><span class="p">.</span><span class="n">MCFLIRT</span><span class="p">()</span>
<span class="n">mcflirt</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">in_file</span> <span class="o">=</span> <span class="s">'slice_timing_corrected.nii.gz'</span>
<span class="n">mcflirt</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">cost</span> <span class="o">=</span> <span class="s">'mutualinfo'</span>
<span class="n">mcflirt</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">ref_vol</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">mcflirt</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">save_plots</span> <span class="o">=</span> <span class="bp">True</span>
<span class="n">mcflirt</span><span class="p">.</span><span class="n">run</span><span class="p">()</span>
</code></pre></div></div>

<p>Visualizing motion parameters:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">motion_params</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="s">'motion_parameters.par'</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">motion_params</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">3</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'Translation (mm)'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">motion_params</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">:])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'Rotation (rad)'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'Volume'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">'motion_parameters.png'</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="step-5-spatial-normalization">Step 5: Spatial Normalization</h2>

<p>To compare brain activity across subjects, individual brains must be transformed to a standard space:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># First, extract brain from structural image
</span><span class="n">bet</span> <span class="o">=</span> <span class="n">fsl</span><span class="p">.</span><span class="n">BET</span><span class="p">()</span>
<span class="n">bet</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">in_file</span> <span class="o">=</span> <span class="s">'structural.nii.gz'</span>
<span class="n">bet</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">out_file</span> <span class="o">=</span> <span class="s">'structural_brain.nii.gz'</span>
<span class="n">bet</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">frac</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">bet</span><span class="p">.</span><span class="n">run</span><span class="p">()</span>

<span class="c1"># Register functional to structural
</span><span class="n">flirt</span> <span class="o">=</span> <span class="n">fsl</span><span class="p">.</span><span class="n">FLIRT</span><span class="p">()</span>
<span class="n">flirt</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">in_file</span> <span class="o">=</span> <span class="s">'motion_corrected.nii.gz'</span>
<span class="n">flirt</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">reference</span> <span class="o">=</span> <span class="s">'structural_brain.nii.gz'</span>
<span class="n">flirt</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">out_file</span> <span class="o">=</span> <span class="s">'func2struct.nii.gz'</span>
<span class="n">flirt</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">out_matrix_file</span> <span class="o">=</span> <span class="s">'func2struct.mat'</span>
<span class="n">flirt</span><span class="p">.</span><span class="n">run</span><span class="p">()</span>

<span class="c1"># Register structural to standard space (MNI)
</span><span class="n">flirt</span> <span class="o">=</span> <span class="n">fsl</span><span class="p">.</span><span class="n">FLIRT</span><span class="p">()</span>
<span class="n">flirt</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">in_file</span> <span class="o">=</span> <span class="s">'structural_brain.nii.gz'</span>
<span class="n">flirt</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">reference</span> <span class="o">=</span> <span class="s">'MNI152_T1_2mm_brain.nii.gz'</span>
<span class="n">flirt</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">out_file</span> <span class="o">=</span> <span class="s">'struct2mni.nii.gz'</span>
<span class="n">flirt</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">out_matrix_file</span> <span class="o">=</span> <span class="s">'struct2mni.mat'</span>
<span class="n">flirt</span><span class="p">.</span><span class="n">run</span><span class="p">()</span>

<span class="c1"># Apply transformations to functional data
</span><span class="n">concat_xfm</span> <span class="o">=</span> <span class="n">fsl</span><span class="p">.</span><span class="n">ConvertXFM</span><span class="p">()</span>
<span class="n">concat_xfm</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">in_file</span> <span class="o">=</span> <span class="s">'func2struct.mat'</span>
<span class="n">concat_xfm</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">in_file2</span> <span class="o">=</span> <span class="s">'struct2mni.mat'</span>
<span class="n">concat_xfm</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">concat_xfm</span> <span class="o">=</span> <span class="bp">True</span>
<span class="n">concat_xfm</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">out_file</span> <span class="o">=</span> <span class="s">'func2mni.mat'</span>
<span class="n">concat_xfm</span><span class="p">.</span><span class="n">run</span><span class="p">()</span>

<span class="n">apply_xfm</span> <span class="o">=</span> <span class="n">fsl</span><span class="p">.</span><span class="n">ApplyXFM</span><span class="p">()</span>
<span class="n">apply_xfm</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">in_file</span> <span class="o">=</span> <span class="s">'motion_corrected.nii.gz'</span>
<span class="n">apply_xfm</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">reference</span> <span class="o">=</span> <span class="s">'MNI152_T1_2mm_brain.nii.gz'</span>
<span class="n">apply_xfm</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">in_matrix_file</span> <span class="o">=</span> <span class="s">'func2mni.mat'</span>
<span class="n">apply_xfm</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">out_file</span> <span class="o">=</span> <span class="s">'func_mni.nii.gz'</span>
<span class="n">apply_xfm</span><span class="p">.</span><span class="n">run</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="step-6-spatial-smoothing">Step 6: Spatial Smoothing</h2>

<p>Smoothing increases signal-to-noise ratio and accommodates anatomical variability:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">smooth</span> <span class="o">=</span> <span class="n">fsl</span><span class="p">.</span><span class="n">Smooth</span><span class="p">()</span>
<span class="n">smooth</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">in_file</span> <span class="o">=</span> <span class="s">'func_mni.nii.gz'</span>
<span class="n">smooth</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">fwhm</span> <span class="o">=</span> <span class="mf">6.0</span>
<span class="n">smooth</span><span class="p">.</span><span class="n">run</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="step-7-temporal-filtering">Step 7: Temporal Filtering</h2>

<p>Remove low-frequency drifts and high-frequency noise:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">filt</span> <span class="o">=</span> <span class="n">fsl</span><span class="p">.</span><span class="n">TemporalFilter</span><span class="p">()</span>
<span class="n">filt</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">in_file</span> <span class="o">=</span> <span class="s">'smoothed_func.nii.gz'</span>
<span class="n">filt</span><span class="p">.</span><span class="n">inputs</span><span class="p">.</span><span class="n">highpass_sigma</span> <span class="o">=</span> <span class="mi">50</span>  <span class="c1"># In seconds for 100s cutoff
</span><span class="n">filt</span><span class="p">.</span><span class="n">run</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="step-8-intensity-normalization">Step 8: Intensity Normalization</h2>

<p>Scale voxel intensities to enable meaningful comparisons:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">image</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="n">load_img</span><span class="p">(</span><span class="s">'filtered_func.nii.gz'</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">img</span><span class="p">.</span><span class="n">get_fdata</span><span class="p">()</span>
<span class="n">mean</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span> <span class="o">/</span> <span class="n">mean</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span>
<span class="n">norm_img</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="n">new_img_like</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
<span class="n">norm_img</span><span class="p">.</span><span class="n">to_filename</span><span class="p">(</span><span class="s">'normalized_func.nii.gz'</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="step-9-quality-control">Step 9: Quality Control</h2>

<p>Always check your preprocessing results for anomalies:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">plotting</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># Create a report of mean, std, and tSNR images
</span><span class="n">img</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="n">load_img</span><span class="p">(</span><span class="s">'normalized_func.nii.gz'</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">img</span><span class="p">.</span><span class="n">get_fdata</span><span class="p">()</span>
<span class="n">mean_img</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="n">new_img_like</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">))</span>
<span class="n">std_img</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="n">new_img_like</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">))</span>
<span class="n">tsnr_img</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="n">new_img_like</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span> <span class="o">/</span> <span class="n">data</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">))</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span>
<span class="n">plotting</span><span class="p">.</span><span class="n">plot_epi</span><span class="p">(</span><span class="n">mean_img</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s">'Mean Image'</span><span class="p">)</span>
<span class="n">plotting</span><span class="p">.</span><span class="n">plot_epi</span><span class="p">(</span><span class="n">std_img</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s">'Standard Deviation'</span><span class="p">)</span>
<span class="n">plotting</span><span class="p">.</span><span class="n">plot_epi</span><span class="p">(</span><span class="n">tsnr_img</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s">'tSNR'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">'quality_control.png'</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="common-preprocessing-workflows">Common Preprocessing Workflows</h2>

<p>Different research questions may require different preprocessing steps. Here are some common workflows:</p>

<ol>
  <li><strong>Task-based fMRI</strong>:
    <ul>
      <li>Slice timing correction</li>
      <li>Motion correction</li>
      <li>Spatial normalization</li>
      <li>Spatial smoothing (5-8mm FWHM)</li>
      <li>Temporal filtering (high-pass, &gt;0.01Hz)</li>
    </ul>
  </li>
  <li><strong>Resting-state fMRI</strong>:
    <ul>
      <li>Motion correction</li>
      <li>Regress out nuisance variables (CSF, WM signals, motion parameters)</li>
      <li>Spatial normalization</li>
      <li>Spatial smoothing (4-6mm FWHM)</li>
      <li>Bandpass filtering (0.01-0.08Hz)</li>
    </ul>
  </li>
  <li><strong>Multi-echo fMRI</strong>:
    <ul>
      <li>Combine echoes using optimal combination or ICA-based denoising</li>
      <li>Motion correction</li>
      <li>Spatial normalization</li>
      <li>Minimal or no spatial smoothing</li>
    </ul>
  </li>
</ol>

<h2 id="conclusion">Conclusion</h2>

<p>Proper preprocessing is essential for reliable fMRI analysis. The choices made during preprocessing can significantly impact your results, so it’s crucial to understand each step and make informed decisions based on your specific research question.</p>

<p>In future tutorials, we’ll cover statistical analysis methods for extracting meaningful patterns from your preprocessed fMRI data.</p>

<h2 id="references">References</h2>

<ol>
  <li>Poldrack, R. A., Mumford, J. A., &amp; Nichols, T. E. (2011). Handbook of functional MRI data analysis. Cambridge University Press.</li>
  <li>Jenkinson, M., Beckmann, C. F., Behrens, T. E., Woolrich, M. W., &amp; Smith, S. M. (2012). FSL. Neuroimage, 62(2), 782-790.</li>
  <li>Esteban, O., Markiewicz, C. J., Blair, R. W., et al. (2019). fMRIPrep: a robust preprocessing pipeline for functional MRI. Nature Methods, 16(1), 111-116.</li>
</ol>]]></content><author><name>Jim Jing</name></author><category term="tutorials" /><category term="fMRI" /><category term="preprocessing" /><category term="neuroimaging" /><category term="tutorial" /><summary type="html"><![CDATA[A step-by-step tutorial on preprocessing functional MRI data, covering motion correction, slice timing, spatial normalization, and more.]]></summary></entry></feed>